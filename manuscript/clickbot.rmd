---
title             : "Changing coronavirus vaccination attitudes"
shorttitle        : "Clickbot replication"



author:
  - name: Charlotte Brand
    affiliation: '1'
    role:
      - Conceptualization
      - Project Administration
      - Data collection and analysis
      - Visualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
    corresponding: yes
    email: c.brand@sheffield.ac.uk
    address: Enter postal address here
  - name: Tom Stafford
    affiliation: '2'
    role:
      - Conceptualization
      - Funding Acquisition
      - Writing - Review & Editing
    email: t.stafford@sheffield.com

affiliation:
  - id: '1'
    institution: University of Sheffield
  - id: '2'
    institution: University of Sheffield
    
authornote: |
  Contents of this author note autogenerated using Tenzing https://martonbalazskovacs.shinyapps.io/tenzing/ <!-- Read more https://medium.com/@ceptional/announcing-tenzing-ceca6789d88c and https://apastyle.apa.org/blog/author-note -->


abstract: |
  A recent study found that interacting with a chatbot for around five minutes led to an increase in Covid-19 vaccination attitudes and intentions in a French population, compared to a control condition (Altay et al. 2020). We wanted test this effect with a UK population whilst making some key modifications. Firstly we wanted to control the amount of information provided by the chatbot compared to the control condition, as well as the time spent with the information, how the trustworthiness of the information was communicated, and the interactivity of the information. By isolating the effect of the ‘choice of information’ in our experimental condition, we wished to discover what it was about the chatbot that was more effective than their control. In our control condition, participants were randomly exposed to four dialogues of Covid-19 vaccination information in a Q&A format of 200-500 words each, each containing two-three follow-up questions. Our experimental condition differed only in that participants could choose the four dialogues they were exposed to, and were given a choice of Five Question topics to choose from. Like the Altay Chatbot, we saw an increase in positive attitudes towards vaccination, as well as an increase in intention to get vaccinated, after viewing the information. Crucially, we found no difference in our conditions, in that choosing the questions did not increase vaccine attitudes, nor did it increase vaccine intentions, compared to randomly displaying the information. This is in contrast to Altay’s experiment in which the Chatbot had a significantly greater effect than their Control. Importantly, in Altay’s experiment their Control condition a) consisted of significantly less information b) did not provide information about the trustworthiness of the information and c) led to participants spending less time with the information. Similarly to the previous study, we also found an effect of time spent with the information, across both conditions, in that those who spent between 4 and 16 minutes (above the median) with the information were more likely to increase both their attitudes and their vaccination intentions. Another crucial difference is our sample, in that we specifically targeted those who were already either against or neutral towards covid-19 vaccinations specifically, and screened-out  any who were already positive towards covid-19 vaccinations


note              : \textcolor{red}{This paper is a pre-print and has not yet been peer-reviewed}



bibliography      : ["references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "jou"
output            : papaja::apa6_pdf
#output            : bookdown::html_document2

---

```{r setup,}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height=2, fig.width=4)
library(rethinking)
#library(here)
```

`r figsize<-'68%'`

# Introduction

You will find it useful to add 3 and 5 to make `r 3+5` compare the output PDF document with the .rmd document. This latter item is the thing you edit to produce the PDF. 

Communicating the effectiveness, necessity and safety of vaccination to the general public is arguably one of science communication’s most important and emblematic challenges. Appropriately, huge amounts of attention and research effort has been directed towards how to increase Covid-19 vaccination uptake. Due to the urgency and impact of the problem, a multi-pronged attack is warranted, and thus research rightly spans many different strategies, from pre-empting misinformation on social media (Vraga & Bode 2021), presenting information on the comparison of Covid-19 symptoms to vaccination side-effects (Thorpe et al. 2021), presenting information on the timeline of vaccine development (Thorpe et al. 2021), different styles of myth-busting (Challenger et al. 20201), the use of social norms (Moehring et al. 2021) and even chatbots (Altay et al. 2020), all with varying levels of success.  

Do I need a para here about chatbots in general? Usually used for tasks, only just starting to have real interest in their ability to have constructive dialogue etc? Check Altay’s GMO chatbot paper intro for inspo. 

Here we focus on the use of chatbots for attitude change. The use of chatbots to change attitudes is not restricted to vaccination hesitancy, and has previously been explored in the context of GMO attitudes (Altay et al. 2021). One such experiment that looked at the effect of a chatbot on GMO attitudes found that the chatbot had a positive effect on GMO attitudes compared to two comparisons; 1) a short description of GMOs 2) a description of the consensus scientific view, but it did not have a positive effect compared to a third condition that contained counterarguments. In this counterargument condition, participants were exposed to all GMO beliefs and counterarguments at once, rather than choosing which counterarguments to interact with. This suggested that choice of information, i.e. interactivity, was not the driving factor behind the success of the chatbot. Crucially, they did find that the positive attitudes were mediated by time spent in the conditions, and that people spent on average longer in the counterargument condition. They also found that in the chatbot condition, for three out of four arguments, the best predictor for selecting a given argument was how negative their initial view towards it was, so participants did seem to select arguments based on their concerns. 

This idea that choice of information is important chimes with research into people’s apparent preference for choosing their own actions, making their own decisions, and choosing what path to take, even if on average it leads to worse outcomes (Babadia-Suarez et al. 2017). More stuff here about choice? Or merge this with the previous para?

A recent study found that exposure to a chatbot increases positive attitudes towards Covid-19 vaccination compared to a control of 90 words (Altay et al. 2020). We would like to know what it is about chatbots that helps increase vaccination attitudes, as this experiment does not tell us whether it is the a) amount of information b) time spent with the information c) interactivity or choice of information or  d) trustworthiness of the information.  Role of trust “why should I trust you” section (Tom’s trust ref?)

To address this, we used the same information but created two conditions in which the only difference was the interactivity of the information, but the amount of information, time spent on the information and trustworthiness of the information was the same for both conditions.


For reviews of this topic see @wickelgren1977speed; @heitz2014speed. Here is another example reference [e.g. @stafford2020] 



# Method

## Participants




# Analysis

Our hypotheses, predictions and analyses were preregistered before data collection at https://osf.io/t4gav. All of our data, code and analysis scripts are available at www.github.com/lottybrand/clickbot_analysis 

In line with our preregistration, we analysed whether participants changed their intention to be vaccinated using a Bayesian binomial regression model with the Rethinking package in R (@mcelreath2018statistical). 


# Results

```{r results='hide'}
#copying from https://bookdown.org/yihui/rmarkdown/r-code.html
#this is some R code which evaluates when you make the document
#
source("../results/loading_saved_models.R")
precis(modelnos)[2,1]
precis(modelnos)[2,3]
precis(modelnos)[2,4]
precis(model1)[2,1]
precis(model1)[2,3]
precis(model1)[2,4]
```

## Preregistered hypotheses

We found that participants’ unwillingness to have the vaccine decreased after both conditions (mean model estimate: `r precis(modelnos)[2,1] `, 89% Credible Interval: `r precis(modelnos)[2,3] `, `r precis(modelnos)[2,4] ` ). This was against prediction 1; those in the choice condition were not more likely to show an increase in their intention to have the vaccine compared to the control condition (mean: `r precis(model1)[2,1] `, 89% CI: `r precis(model1)[2,3] `, `r precis(model1)[2,4] `). 

(mention the model comparison here?) This change in vaccination attitudes can be seen in Figure 1 \@ref(fig1:figure1), which shows the raw vaccination attitude ratings before and after the experiment. Figures displaying the differences in vaccination attitudes between different scale items can be found in the supplementary material. 

Increase in average vaccination attitude can be seen in the violin plot. 

```{r figure1, fig1.cap="Density plot of vaccination attitudes before and after the experiment", fig.align="center", out.width="75%"}
knitr::include_graphics("../plots/raw_density.png")
```





See Figure \@ref(fig:ourhistogram). Of course we could draw all sorts of things, but this is a proof-of-concept. Finally, let's run a t-test and integrate the results into the text.

```{r}
#note that seperate code chunks remember variables from previous chunks, so we don't need to reload the data



```


Unanswered questions: Is this the best way to integrate values into text? Why is the df not an integer? What is the best way to define figure sizes so you get nice and/or consistent sizing across document formats?

# Discussion

Make your document by opening .Rmd file in RStudio and clicking 'knit' 

Rmarkdown is good [@rmarkdowncite]. Need to change reference style? Change one line. Need to submit as PDF rather than .DOC? Just click 'Word' as output rather than 'PDF' (instructions here https://rmarkdown.rstudio.com/articles_docx.html). Need to change to two column style to make a nice pre-print? Again, simple - just change one line! In line 40 'class             : "man"' gives you manuscript style; "jou" gives you two column style.

To port to your own project just copy across these files:

* example_manuscript.rmd
* apa6.cls - style file which makes everything look APA format nice
* references.bib - information on references in bibtex format
* figs folder - where images integrated into the manuscript are kept

## Main conclusions

Of course, there's more effort in installing and learning and correctly marking up your document in the first place, but it is worth it


```{r results="hide"}
#how to get a citation for packages you use
citation('papaja')
```

# References
